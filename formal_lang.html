<h1 id="top">Formal Description Language</h1>
<p>
	Honestly, I was kinda mucking about, but I think I found a cozy little language (or should I say, algebra?) that can both describe data structures and programs.
	On its own, it doesn't talk about anything that hasn't already been talked in mathematics or information/computation/type theory, but I appreciate its symplicity,
	and, as always, have some fun ideas about a possible practical application.
</p>
<h2>Table of contents</h2>
<ul>
	<li><a href="#outline">Outline</a></li>
	<ul>
		<li><a href="#comma">Comma</a></li>
		<li><a href="#space">Space</a></li>
		<li><a href="#equality">Equality</a></li>
	</ul>
	<li><a href="#cardinality">Cardinality</a></li>
	<li><a href="#complex_operations">Defining more complicated operations</a></li>
	<ul>
		<li><a href="#modular_addition">Case study: Modular Addition</a></li>
	</ul>
<!--<li><a href="#"></a></li>-->
</ul>
<h2 id="outline">Outline</h2>
<p>
	It starts with a very basic set of rules. First, we define <code>:=</code>.
	It allows us to substitute the left side with the right side, whenever we encounter the left side in an expression.<br/>
	To give an example:
<pre><code> a := b;</code></pre>
	This means that, whenever an <code>a</code> is encountered, we can substitute it for a <code>b</code>,
	but not the other way around.
</p><p>
	Next, we define 3 different operators, that can be used to form expressions.
</p>

<h3 id="comma">Comma</h3>
<p>
	The first is <code>,</code>, a comma. A comma denotes a list of possible symbols that something can be.<br/>
	As an example:
<pre><code>b := F, T;
d := 0, 1, 2, 3, 4, 5, 6, 7, 8, 9;</code></pre>
	The <code>b</code> is a boolean. it can be either True or False.
	<code>d</code> is a decimal digit, it can be any symbol between 0 and 9.
	In type theory, this would be considered a 'sum type' (more on this later).
</p>

<h3 id="space">Space</h3>
<p>
	The second operator is <code> </code>, empty space. One might call it a stretch to call spaces 'operators',
	but they do denote a unique meaning: concatenation.<br/>
	Here, we define <code>u</code> to be two <code>b</code> symbols (booleans).
<pre><code>u := b b;</code></pre>
	Each boolean could be either true or false, so this <code>u</code> symbol can have 4 possible states.
	Based on this information, it might not be surprising that this is called a 'product type' in type theory (again, remember this for later).
</p>

<h3 id="equality">Equality</h3>
<p>
	The third operator is <code>=</code>, equality. It asserts that a certain symbol is equal to another.
	In the case of 'sum type'-symbols, this means that an equality expression specifies which sub-symbol that symbol embodies.<br/>
	The most basic case of this is in defining 'values' for 'constants', while maintaining their identity as an originally generalized 'type':
<pre><code>Y := b = T;</code></pre>
	In this usage, <code>Y</code> is a constant, <code>T</code> is a value, and <code>b</code> is, in essence, its type.
</p><p>
	There is a more interesting use of <code>=</code>, and that is that it gives us the ability to define other operations,
	by placing it on the left of a definition statement.
	For example, let's define <code>~</code>, the logic negation operator, for <code>b</code>:
<pre><code>~(b = T) := (b = F);
~(b = F) := (b = T);
</code></pre>
	Now, we immediately notice that I sneakily introduced parentheses, but those are purely 'syntactic sugar',
	to denote clear precedence. (We might prove at a later date that they can be notationed away.)<br>
	The next notable thing is the seeming redundancy of the notation. Why did I use <code>(b = T)</code> and the like,
	instead of simply:
<pre><code>~T := F;
~F := T;
</code></pre>
	It is because we were defining the <code>~</code> operator on <code>b</code>, and not on the underlying symbols.
	As mentioned, the definition statement is one-directional. Left becomes Right, not the other way around.
	For a simple unary operation like negation, the difference of using the 'overarching' symbol does not matter,
	but on operations with more than one argument, and more complex types, the amount of possible interactions
	increases significantly. So if the operation allows for it, it would help if we could generalize, to cut down
	on amount of cases we have to write out. Before we start doing that, we have to lay out some important terms:
</p>

<h2 id="cardinality">Cardinality</h2>
<p>
	Recall earlier that we called things with the comma 'sum types' and things with spaces 'product types'.
	These names derive from how many states a symbol can be in.
	The earlier defined decimal digit <code>d</code> is practical to use as an example for this.
<pre><code>d := 0, 1, 2, 3, 4, 5, 6, 7, 8, 9;</code></pre>
	It can 'contain' any symbol from 0 to 9; 10 possible states. We will call this its <i>cardinality</i>,
	the amount of states a symbol or expression can be in. Booleans have a cardinality of 2.
</p><p>
	But where do the names 'sum type' and 'product type' come from? To explain this, let's look at the following symbol:
<pre><code>q := b, d;</code></pre>
	<code>q</code> can be <code>b</code> or <code>d</code>, <code>b</code> has a cardinality of 2, <code>d</code> has a cardinality of 10.
	Because <code>q</code> can be all the states of <code>b</code>, or all the states of <code>d</code>,
	<code>q</code> gets a cardinality of 12, which is the <i>sum</i> of the cardinality of the symbols it is made up from.<br/>
	Because this is not type theory, and we want to talk about more than just types,
	we will call symbols and expressions that have this property <i>sum-like</i>.
</p><p>
	For 'product type' (henceforth <i>product-like</i>) symbols and expressions, we can provide a very similar example:
<pre><code>p := b d;</code></pre>
	<code>p</code> contains both a <code>b</code> and <code>d</code>, so it's possible amount of states is the cardinality of <code>b</code> multiplied
	by the cardinality of <code>d</code>: 2×10 = 20. Indeed, the <i>product</i> of the consituant cardinalities.
</p><p>
	What about symbols like <code>T</code> or <code>5</code>, that we used without giving them their own definition?
	They simply have a cardinality of 1; they can only ever be themselves.
</p>

<h2 id="complex_operations">Defining more complicated operations</h2>
<p>
	At the end of the <a href="#equality">chapter on Equality</a>, we briefly discussed how it might work in
	our favor to 'generalize' on operation definitions, and how it helps to use sum-like symbols for this.
</p><p>
	As a first, 'low stakes' example, let's look at <code>&</code>, the logic conjunction operator.
	If we were to define it using purely <code>T</code> and <code>F</code>, it would look like this:
<pre><code>T & T := T;
F & T := F;
T & F := F;
F & F := F;
</code></pre>
	But, there is somewhat of a redundancy here. When either of the arguments is <code>F</code>,
	we know the result will also be <code>F</code>, regardless of the other argument. By using the <code>b</code>
	symbol, we can actually implement this generalization.<br/>
	We start by rewriting our first version to take booleans:
<pre><code>(b = T) & (b = T) := (b = T);
(b = F) & (b = T) := (b = F);
(b = T) & (b = F) := (b = F);
(b = F) & (b = F) := (b = F);
</code></pre>
	Then, we implement our generalization by omitting the equality check on one of the arguments if the other is <code>F</code>.
<pre><code>(b = T) & (b = T) := (b = T);
(b = F) &  b      := (b = F);
 b      & (b = F) := (b = F);
</code></pre>
	In doing this, you'll notice that the last case on the previous definition (<code>(b = F) & (b = F) := (b = F);</code>) has been generalized out.
	The definition now consists of three statements, instead of four.<br/>
	One could argue that these gains are marginal at best, so let's look at a more extreme case.
</p>

<h3 id="modular_addition">Case study: Modular Addition</h3>
<p>

</p>
<!--
	Recall that concatenating symbols increases cardinality by the product of the substituant cardinalites.
	Using the earlier defined decimal digit <code>d</code> for an example, if we wanted to describe an operator <code>#</code>
	between two <code>d</code> symbols, that would look like:
<pre><code>d # d</code></pre>
	Each <code>d</code> has a cardinality of 10, and the <code>#</code> is never defined in isolation (this is what makes it an operator),
	it has the cardinality of itself: 1. It can only ever be <code>#</code>.<br/>
	That means the cardinality of the given expression is 10×1×10 = 100.
	Not needing to specify every subvalue would be advisable if we can help it.
</p><p>
	For a hands-on example of this, let's look at defining <code>&</code>, the logic conjunction operator.
	We now know that the maximum amount of statements we'd need to completely describe <code>&</code> would be 4 (since it takes two booleans).<br/>
	Something like this:
<pre><code>(b = T) & (b = T) := (b = T);
(b = F) & (b = T) := (b = F);
(b = T) & (b = F) := (b = F);
(b = F) & (b = F) := (b = F);
</code></pre>
	However, when either of the arguments is <code>F</code>, we know the result will indeed be <code>F</code>, no matter the other argument.
	So, <code>&</code> can be simplified by several terms:
<pre><code>(b = T) & (b = T) := (b = T);
(b = F) & b := (b = F);
b & (b = F) := (b = F);
</code></pre>
</p>-->

<!--
<pre><code></code></pre>
-->
